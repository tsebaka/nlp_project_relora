{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20589bda-fe8c-4787-a40e-20004543aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"/home/jovyan/.local/share/virtualenvs/ptls-experiments-w-dEu3oS/lib/python3.8/site-packages\")\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb084d3-5cfc-46a4-abb5-fd728a4bdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import lightning as L\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig\n",
    "from src.modules.training_modules import ReloraModuleForClassification\n",
    "from src.dataset.dataset import EssayDataset\n",
    "from src.metric.metric import quadratic_weighted_kappa\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a30433-9cec-4f25-a19f-3270745fa8b9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df047b2-8a2b-480d-8265-7a691b1ca56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"src/data/train.csv\")\n",
    "train_set, val_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = EssayDataset(_, train_set)\n",
    "eval_dataset = EssayDataset(_, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0134947-1eda-4576-9565-e09c5271770e",
   "metadata": {},
   "source": [
    "# Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec89be0e-1705-40e0-868a-81a62fcc4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 234\n",
      "/home/jovyan/.local/share/virtualenvs/ptls-experiments-w-dEu3oS/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "project_name = \"ReLoRA\"\n",
    "dataset_shards = 1\n",
    "\n",
    "max_epochs = 10\n",
    "lora_merge_epochs = 1\n",
    "learning_rate = 1e-5\n",
    "max_steps = 1e5\n",
    "max_val_steps = 1e4\n",
    "\n",
    "L.seed_everything(234)\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "model_class = LlamaForSequenceClassificationmodel_path = \"philschmid/llama-2-7b-instruction-generator\"\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.1, bias=\"none\", inference_mode=False)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_class = AutoModelForSequenceClassification\n",
    "model_path = \"microsoft/deberta-v3-large\"\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.01, bias=\"none\", inference_mode=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0d143-e37e-4d06-a2fa-776df4e000fa",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d9fb66-db2c-4c44-abf7-3a189df562eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/.local/share/virtualenvs/ptls-experiments-w-dEu3oS/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                               | Params\n",
      "-------------------------------------------------------------\n",
      "0 | loss  | MSELoss                            | 0     \n",
      "1 | model | DebertaV2ForSequenceClassification | 435 M \n",
      "-------------------------------------------------------------\n",
      "435 M     Trainable params\n",
      "0         Non-trainable params\n",
      "435 M     Total params\n",
      "1,740.251 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f298e93db9f4bdfb92314815dbc7bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "model = ReloraModuleForClassification(model_class=model_class, model_path=model_path, lora_config=lora_config, lora_merge_freq=1,\n",
    "                                      train_dataset=train_dataset, eval_dataset=eval_dataset, learning_rate=learning_rate)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=3, log_every_n_steps=1,\n",
    "                    limit_train_batches=1e5, limit_val_batches=1e4, reload_dataloaders_every_n_epochs=100)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb88ea3-a6b5-49f9-aade-2ffa2865c9fd",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94752e3-e7be-42c0-b4f8-371d3f845e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6297a4c9c14495a60916fdb27b8fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3175772/186579518.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(eval_dataset[i][\"input_ids\"])\n",
      "/tmp/ipykernel_3175772/186579518.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(eval_dataset[i][\"attention_mask\"])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = []\n",
    "labels = []\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(len(eval_dataset))):\n",
    "    torch.cuda.empty_cache()\n",
    "    input_ids = torch.tensor(eval_dataset[i][\"input_ids\"])\n",
    "    attention_mask = torch.tensor(eval_dataset[i][\"attention_mask\"])\n",
    "    model.to(device)\n",
    "    outputs.append(model.forward([input_ids.view(1, -1).to(device), attention_mask.view(1, -1).to(device)])[\"logits\"].view(-1).detach().cpu())\n",
    "    labels.append(eval_dataset[i][\"labels\"].detach().cpu())\n",
    "    \n",
    "quadratic_weighted_kappa(np.array(torch.stack(outputs).view(-1).numpy()), np.array(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls-experiments",
   "language": "python",
   "name": "ptls-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
